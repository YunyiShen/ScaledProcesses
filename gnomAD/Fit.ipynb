{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db3b331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/lshzpfr91mv6j94gc2lyztjw0000gr/T/ipykernel_14680/2171367517.py:13: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../utils_folder/')\n",
    "import time\n",
    "from utils_GD import *\n",
    "from utils_IBP import *\n",
    "from utils_jack import *\n",
    "from utils_gt import *\n",
    "from utils_unseen import *\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c0d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N : 50\n",
      "\t afr\n",
      "\t\t 8000\n",
      "\t amr\n",
      "\t\t 17200\n",
      "\t asj\n",
      "\t\t 5000\n",
      "\t eas\n",
      "\t\t 9000\n",
      "\t eas_oea\n",
      "\t\t 7200\n",
      "\t fin\n",
      "\t\t 10800\n",
      "\t nfe_bgr\n",
      "\t\t 1200\n",
      "\t nfe_est\n",
      "\t\t 120\n",
      "\t nfe_nwe\n",
      "\t\t 21000\n",
      "\t nfe_seu\n",
      "\t\t 5600\n",
      "\t nfe_swe\n",
      "\t\t 13000\n",
      "\t sas\n",
      "\t\t 15200\n",
      "\t oth\n",
      "\t\t 3000\n",
      "N : 100\n",
      "\t afr\n",
      "\t\t 8000\n",
      "\t amr\n",
      "\t\t 17200\n",
      "\t asj\n",
      "\t\t 5000\n",
      "\t eas\n",
      "\t\t 9000\n",
      "\t eas_oea\n",
      "\t\t 7200\n",
      "\t fin\n",
      "\t\t 10800\n",
      "\t nfe_bgr\n",
      "\t\t 1200\n",
      "\t nfe_est\n",
      "\t\t 120\n",
      "\t nfe_nwe\n",
      "\t\t 21000\n",
      "\t nfe_seu\n",
      "\t\t 5600\n",
      "\t nfe_swe\n",
      "\t\t 13000\n",
      "\t sas\n",
      "\t\t 15200\n",
      "\t oth\n",
      "\t\t 3000\n",
      "N : 200\n",
      "\t afr\n",
      "\t\t 8000\n",
      "\t amr\n",
      "\t\t 17200\n",
      "\t asj\n",
      "\t\t 5000\n",
      "\t eas\n",
      "\t\t 9000\n",
      "\t eas_oea\n",
      "\t\t 7200\n",
      "\t fin\n",
      "\t\t 10800\n",
      "\t nfe_bgr\n",
      "\t\t 1200\n",
      "\t nfe_est\n",
      "\t\tHm, file not found. Skipping!\n",
      "\t nfe_nwe\n",
      "\t\tHm, file not found. Skipping!\n",
      "\t nfe_seu\n",
      "\t\tHm, file not found. Skipping!\n",
      "\t nfe_swe\n",
      "\t\tHm, file not found. Skipping!\n",
      "\t sas\n",
      "\t\tHm, file not found. Skipping!\n",
      "\t oth\n",
      "\t\tHm, file not found. Skipping!\n"
     ]
    }
   ],
   "source": [
    "N_ls = [50,100,200]\n",
    "population_ls = ['afr', 'amr', 'asj', 'eas', 'eas_oea', 'fin', 'nfe_bgr', 'nfe_est', 'nfe_nwe', 'nfe_seu', 'nfe_swe', 'sas', 'oth']\n",
    "\n",
    "num_its = 10\n",
    "kappa = .5\n",
    "status = False\n",
    "results = {}\n",
    "for N in N_ls:\n",
    "    print('N :', N)\n",
    "    results[N] = {}\n",
    "    for p, population in enumerate(population_ls):\n",
    "        \n",
    "        print('\\t', population)\n",
    "    \n",
    "        results[N][population] = {}\n",
    "\n",
    "        try:\n",
    "            sfs = np.load('data/'+population+'/sfs/N_'+str(N)+'.npy', allow_pickle=1) #'+str(population)+'/sfs/N_'+str(N)+'.npy', allow_pickle=1)\n",
    "            cts = np.load('data/'+population+'/cts/N_'+str(N)+'.npy', allow_pickle=1) #'+str(population)+'/sfs/N_'+str(N)+'.npy', allow_pickle=1)\n",
    "            N_tot = len(np.loadtxt('data/'+population+'/cts/all')) - 1\n",
    "\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print('\\t\\tHm, file not found. Skipping!')\n",
    "            continue\n",
    "        stc = time.time()\n",
    "        print('\\t\\t',N_tot)\n",
    "        M = N_tot - N\n",
    "        if M <= 0 :\n",
    "            pass\n",
    "        else:\n",
    "            num_splits = sfs.shape[0]\n",
    "\n",
    "            ### INITIALIZE\n",
    "\n",
    "            ### GD \n",
    "\n",
    "            results[N][population]['GD_params'] = np.zeros([num_splits, 3])\n",
    "            results[N][population]['GD_preds'] = np.zeros([num_splits, N_tot+1])\n",
    "            results[N][population]['GD_lo'], results[N][population]['GD_hi'] = np.zeros([num_splits, N_tot+1]), np.zeros([num_splits, N_tot+1])\n",
    "\n",
    "\n",
    "            # IBP \n",
    "            results[N][population]['IBP_params'] = np.zeros([num_splits, 3])\n",
    "            results[N][population]['IBP_preds'] = np.zeros([num_splits, N_tot+1])\n",
    "            results[N][population]['IBP_lo'], results[N][population]['IBP_hi'] = np.zeros([num_splits, N_tot+1]), np.zeros([num_splits, N_tot+1])\n",
    "\n",
    "\n",
    "            ### JACK\n",
    "\n",
    "            results[N][population]['J_preds'] = np.zeros([num_splits, 4, N_tot+1])\n",
    "\n",
    "\n",
    "            ### GT\n",
    "\n",
    "            results[N][population]['GT_preds'] = np.zeros([num_splits, 2, 2, N_tot+1])\n",
    "\n",
    "            ## LP\n",
    "\n",
    "            results[N][population]['LP_preds'] = np.zeros([num_splits, N_tot+1])\n",
    "\n",
    "\n",
    "            print('\\tStarting ', population, '; N = ', N, '; M = ', M, '; Progress : ', str(100*(p+1)/len(population_ls))[:5], ' %', sep=' ', end='', flush=True)  \n",
    "            results[N][population]['N'] = N\n",
    "            results[N][population]['M'] = M\n",
    "            results[N][population]['cts'] = np.loadtxt('data/'+population+'/cts/all')\n",
    "            train_counts = results[N][population]['cts'][:N+1]\n",
    "            results[N][population]['sfs'] = sfs\n",
    "            results[N][population]['K']  = [np.sum(s) for s in sfs]\n",
    "\n",
    "\n",
    "            for j in tqdm_notebook(range(num_splits)):\n",
    "\n",
    "                cts_ = cts[j]\n",
    "                sfs_ = sfs[j, 1:]\n",
    "                K = cts_[-1]\n",
    "\n",
    "                gd = GD()\n",
    "                \n",
    "                GD_params = gd.regression(train_counts= cts_, num_its=num_its, norm=2, status=status)\n",
    "                GD_preds = np.concatenate([train_counts, K + gd.mean(N, M, K, GD_params)]) \n",
    "                GD_lo, GD_hi = gd.credible_interval(N, M, K, GD_params, width=.99) \n",
    "                GD_lo, GD_hi =  np.concatenate([train_counts, K + GD_lo]), np.concatenate([train_counts, K + GD_hi])\n",
    "\n",
    "                results[N][population]['GD_params'][j] = GD_params\n",
    "                results[N][population]['GD_preds'][j] = GD_preds\n",
    "                results[N][population]['GD_lo'][j], results[N][population]['GD_hi'][j] = GD_lo, GD_hi  \n",
    "\n",
    "                ibp = IBP()\n",
    "                \n",
    "                IBP_params = ibp.regression(train_counts= cts_, num_its=num_its, norm=2, status=status)\n",
    "                IBP_preds = np.concatenate([train_counts, K + ibp.mean(N, M, IBP_params)]) \n",
    "                IBP_lo, IBP_hi = ibp.credible_interval(N, M, IBP_params, width=.99) \n",
    "                IBP_lo, IBP_hi =  np.concatenate([train_counts, K + IBP_lo]), np.concatenate([train_counts, K + IBP_hi])\n",
    "\n",
    "                results[N][population]['IBP_params'][j] = IBP_params\n",
    "                results[N][population]['IBP_preds'][j] = IBP_preds\n",
    "                results[N][population]['IBP_lo'][j], results[N][population]['IBP_hi'][j] = IBP_lo, IBP_hi\n",
    "\n",
    "\n",
    "                # JACKKNIFE\n",
    "\n",
    "                for order in [1,2,3,4]:\n",
    "                    results[N][population]['J_preds'][j, order-1] = predict_jack(N, M, sfs_, train_counts, order)\n",
    "\n",
    "\n",
    "                # GOOD-TOULMIN\n",
    "\n",
    "\n",
    "                results[N][population]['GT_preds'][j,0] = predict_gt(N, M, sfs_, train_counts, 0)\n",
    "                results[N][population]['GT_preds'][j,1] = predict_gt(N, M, sfs_, train_counts, 1)\n",
    "\n",
    "                # LP\n",
    "\n",
    "                results[N][population]['LP_preds'][j] = pred_counts_unseen(sfs_, kappa, N, M)\n",
    "              \n",
    "        np.save('results/new_all_populations_regression', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Retain minimal info for plotting\n",
    "'''\n",
    "\n",
    "res = np.load('results/new_all_populations_regression.npy', allow_pickle=1).item()\n",
    "_res = {}\n",
    "\n",
    "population_names = {}\n",
    "population_names['amr'] = 'Amr.'\n",
    "population_names['eas'] = 'SE. As.'\n",
    "population_names['eas_oea'] = 'Ot. E. As.'\n",
    "population_names['fin'] = 'Fin.'\n",
    "population_names['nfe_seu'] = 'S. Eu.'\n",
    "population_names['nfe_swe'] = 'Swe.'\n",
    "population_names['sas'] = 'S. As.'\n",
    "population_names['oth'] = 'Other'\n",
    "\n",
    "for N in [50,100]:\n",
    "    _res[N]= {}\n",
    "    for p, population in enumerate(population_names):\n",
    "        _res[N][population] = {}\n",
    "        num_boots = res[N][population]['GD_preds'].shape[0]\n",
    "        _res[N][population]['M'] = len(res[N][population]['GD_preds'][0]) - N\n",
    "        N_M = -1\n",
    "        _res[N][population]['K'] = res[N][population]['cts'][N]\n",
    "        _res[N][population]['K_new'] = res[N][population]['cts'][-1] - res[N][population]['cts'][N]\n",
    "        unm = _res[N][population]['K_new'] \n",
    "        _res[N][population]['GD_precision'] = 1-np.sort(np.abs(res[N][population]['GD_preds'][:,N_M] - unm)/unm)\n",
    "        _res[N][population]['IBP_precision'] = 1-np.sort(np.abs(res[N][population]['IBP_preds'][:,N_M] - unm)/unm)\n",
    "        _res[N][population]['LP_precision'] = 1-np.sort(np.abs(res[N][population]['LP_preds'][:,N_M] - unm)/unm)\n",
    "        _res[N][population]['J_precision'] = np.array([1-np.sort(np.abs(res[N][population]['J_preds'][:,o,N_M] - unm)/unm) for o in range(res[N][population]['J_preds'].shape[1])]).reshape(num_boots,4)\n",
    "        _res[N][population]['GT_precision'] = np.array([1-np.sort(np.abs(res[N][population]['GT_preds'][:,s,0,N_M] - unm)/unm) for s in range(2)]).reshape(num_boots,2)\n",
    "        \n",
    "np.save('results/_new_all_populations_regression.npy', _res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
